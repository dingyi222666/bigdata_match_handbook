## 大数据竞赛-基础架构搭建(三)



### 下载Hadoop安装包并解压到/usr/hadoop


```shell
# master安装
mkdir /usr/hadoop
tar -zxvf hadoop-2.7.3.tar.gz -C /usr/hadoop

#复制到其他主机使用scp吧
scp -r /usr/hadoop root@name:/usr
```



### 配置Hadoop环境变量

```shell
echo -e 'export HADOOP_HOME=/usr/hadoop/hadoop-2.7.3\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin' >> /etc/profile && source /etc/profile
# 看情况修改对应的路径
```



### 配置Hadoop运行环境hadoop-env.sh

```shell
cd /usr/hadoop/hadoop-2.7.3/etc/hadoop #具体路径看要求
echo $JAVA_HOME #复制当前路径
vim hadoop-env.sh
# 添加如下
export JAVA_HOME=/usr/java/jdk1.8.0_171
# 注意这里要之前设置的JAVA_HOME

scp hadoop-env.sh root@name:/usr/hadoop/hadoop-2.7.3/etc/hadoop
# 直接复制到其他主机上

```

> 以下的操作请确保master的文件夹位于HADOOP_HOME/etc/hadoop

### 设置全局参数

```shell
vim core-site.xml
```

然后添加如下内容

```xml
<!-- 定义文件系统的实现，默认是file:///本地文件系统  需要我们改成 hdfs://分布式文件存储系统   -->
<property>
	<name>fs.default.name</name>
	<value>hdfs://master:9000</value>
</property>
<!-- 临时数据存放的位置（Hadoop安装目录下的临时文件） -->
<property>
	<name>hadoop.tmp.dir</name>
	<value>/usr/hadoop/hadoop-2.7.3/hdfs/tmp</value>
</property>
```

推荐使用scp复制到其他主机上

```shell
scp core-site.xml root@name:/usr/hadoop/hadoop-2.7.3/etc/hadoop
```



### 设置HDFS参数

```shell
vim hdfs-site.xml
```

然后添加如下内容

```xml
<!-- 配置系统自动数据备份数量为2份(默认是3份) -->
<property>
<name>dfs.replication</name>
<value>2</value>
</property>
<!-- NameNode 元数据存放位置（初始化时name文件夹才会生成） -->
<property>
<name>dfs.namenode.name.dir</name>
<value>file:/usr/hadoop/hadoop-2.7.3/hdfs/name</value>
<final>true</final>
</property>
<!-- DataNode在本地磁盘存放block的位置（在开启整个集群后，data文件夹才会生成） -->
<property>
<name>dfs.datanode.data.dir</name>
<value>file:/usr/hadoop/hadoop-2.7.3/hdfs/data</value>
<final>true</final>
</property>
```

还是用scp，方便

```shell
scp hdfs-site.xml root@name:/usr/hadoop/hadoop-2.7.3/etc/hadoop
```



### 设置YARN运行环境

```shell
vim yarn-env.sh
echo $JAVA_HOME #复制当前路径
# 添加如下
export JAVA_HOME=/usr/java/jdk1.8.0_171
# 注意这里要之前设置的JAVA_HOME

scp yarn-env.sh root@name:/usr/hadoop/hadoop-2.7.3/etc/hadoop
# 直接复制到其他主机上
```



### 设置YARN核心参数

```shell
vim yarn-site.xml
```

然后添加如下内容 注意端口号

```xml
<!-- RM对客户端暴露的地址，客户端通过该地址向RM提交应用程序等 -->
<property>
<name>yarn.resourcemanager.address</name>
<value>master:18040</value>
</property>
<!-- RM对AM暴露的地址，AM通过地址想RM申请资源，释放资源等 -->
<property>
<name>yarn.resourcemanager.scheduler.address</name>
<value>master:18030</value>
</property>
<!-- RM对外暴露的web  http地址，用户可通过该地址在浏览器中查看集群信息 -->
<property>
<name>yarn.resourcemanager.webapp.address</name>
<value>master:18088</value>
</property>
<!-- RM对NM暴露地址，NM通过该地址向RM汇报心跳，领取任务等 -->
<property>
<name>yarn.resourcemanager.resource-tracker.address</name>
<value>master:18025</value>
</property>
<!-- 管理员可以通过该地址向RM发送管理命令等 -->
<property>
<name>yarn.resourcemanager.admin.address</name>
<value>master:18141</value>
</property>
<!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序 -->
<!-- 指定reduce获取数据的方式 -->
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<!--  -->
<property>
<name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapreduce.ShuffleHandler</value>
</property>

```

还是 scp

```shell
scp yarn-site.xml root@name:/usr/hadoop/hadoop-2.7.3/etc/hadoop
```



### 设置计算框架参数，指定MR运行在yarn上

```shell
# 默认是没有这个参数的 先cp下
cp mapred-site.xml.template mapred-site.xml && vim mapred-site.xml
```

然后添加如下内容

```xml
<!-- 指定mapreduce运行在yarn集群上面 -->
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
```

scp

```ssh
scp mapred-site.xml root@name:/usr/hadoop/hadoop-2.7.3/etc/hadoop
```



###  设置节点文件，要求master为主节点； slave1、slave2为子节点

```shell
echo master > master && echo slave1 > slaves && echo slave2 >> slaves #注意最后一个是要追加写入的
```

然后还是scp

```shell
scp master slaves root@name:/usr/hadoop/hadoop-2.7.3/etc/hadoop
```

### 文件系统格式化

> 仅在master节点执行

```shell
hadoop namenode -format
```

出现以下界面即为成功。

![png](https://img-blog.csdnimg.cn/20210902193823669.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAcXFfNTMzODMzNDk=,size_20,color_FFFFFF,t_70,g_se,x_16)



### 启动Hadoop集群

> 仅在master节点执行

```shell
start-all.sh start
```

